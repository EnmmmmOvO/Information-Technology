{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMP6713  - Natural Language Processing – 25T1\n",
    "\n",
    "### Tutorial – Week 7\n",
    "\n",
    "\n",
    "Fine-tuning BERT for a classification task is a fundamental NLP skill that you must be conversant with. The notebook you will use in this tutorial is a simple BERT-based model for sentiment classification. Work through the TODOs in the notebook to train and test your models.\n",
    "\n",
    "The completion of this tutorial will enable you with skills in fine-tuning BERT-based models for sequence classification tasks.\n",
    "\n",
    "\n",
    "You may use HuggingFace documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pv16FVT8ebvn"
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CcSwzP7LaqR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJCJwYcgLcyP"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = # TODO: Load \"sst2\" dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLqRUntmMNJw"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#TODO: What are other models possible? \n",
    "# Add names corresponding to RoBERTa, DistilBert and different variants of BERT\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    column_name = # TODO Select appropriate column name\n",
    "    return tokenizer(examples[column_name], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tok = # TODO use 'map' on the loaded dataset to tokenize all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_J4h539hMxND"
   },
   "outputs": [],
   "source": [
    "train = tok[\"train\"].shuffle(seed=42).select(range(500))\n",
    "eval = tok[\"validation\"].shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sH8pdbqzOOp1",
    "outputId": "35df4bcf-0bcd-4fc9-b81b-6b8f8a5e817f"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = #TODO Load the model; assign to device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGtioiVzORgR"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = #TODO Assign necessary training arguments. \n",
    "# Try selecting learning rates, and analyse the time taken and corresponding losses.\n",
    "# Similarly, experiment with number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4q6YJXyHPGD6",
    "outputId": "e1f6dc6b-0877-4ebf-d13e-f76a3971f113"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7N6vXp6PM4L"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "m8OjDxx4PUjS",
    "outputId": "107e3b7e-2947-4f32-9171-42a0e1a2cf03"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oikxLyOrRJZ0",
    "outputId": "691a5aaa-67b9-432b-ae9a-7407abb9ef9f"
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IE5kkFacdL2p"
   },
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    tokens = #TODO Tokenize the input sentence\n",
    "    # TODO Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = #TODO Get output from the model\n",
    "        logits = #TODO Select the logits \n",
    "        predicted_class = #TODO Apply softmax and obtain the prediction as an argma\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1p-1GOXdPwg",
    "outputId": "cf5c5e7c-6c90-4e4c-9b47-e82867517a88"
   },
   "outputs": [],
   "source": [
    "# TODO Call the predict function on a few example sentences"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
