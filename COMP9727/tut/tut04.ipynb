{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTsTjSBvp2k_"
   },
   "source": [
    "# **COMP9727 Recommender Systems**\n",
    "## Tutorial Week 4: Association Rule Mining\n",
    "\n",
    "@Author: **Mingqin Yu**\n",
    "\n",
    "@Reviewer: **Wayne Wobcke**\n",
    "\n",
    "### Objective\n",
    "\n",
    "The aim of the tutorial is to become more familiar with association rule mining and the Apriori algorithm through a simple example. This approach may be useful for session-based web page recommendation or generating critiques for knowledge-based recommender systems.\n",
    "\n",
    "### Before the tutorial\n",
    "\n",
    "1. Review the lecture material on association rule mining and the Apriori algorithm.\n",
    "\n",
    "2. Read, understand and run all the code in the Data Mining pipeline below, and come prepared to discuss the answers to some of the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qP3Aez8SqXz1"
   },
   "source": [
    "## Data Mining Pipeline\n",
    "\n",
    "1. **Environment Setup**\n",
    "   - Install libraries and tools\n",
    "   - Load data\n",
    "2. **Apriori Algorithm Implementation**\n",
    "   - Transform transaction data into a binary matrix representation\n",
    "   - Apriori algorithm\n",
    "   - Generate frequent itemsets using a support threshold\n",
    "   - Generate association rules based on a confidence threshold\n",
    "3. **User Profile-Based Recommendations**\n",
    "   - Merge traditional association rule recommendations with user profile data\n",
    "   - Demonstrate how user profiles can further refine recommendations\n",
    "\n",
    "**Specific Learning Objectives**\n",
    "\n",
    "1. **Understand**\n",
    "   - The significance and application of association rule mining in the context of recommender systems\n",
    "   - The use of metrics such as support and confidence\n",
    "2. **Apply**\n",
    "   - Set up a Python environment for implementing association rule mining\n",
    "   - Transform transactional data into a suitable format for rule mining\n",
    "   - Run the Apriori algorithm to extract frequent itemsets from transaction data\n",
    "3. **Analyse**\n",
    "   - User profile data to enhance the quality of recommendations\n",
    "4. **Evaluate**\n",
    "   - The effectiveness of the recommender system on sample data\n",
    "   - The balance between user-specific recommendations and item-based recommendations\n",
    "   - Visualize and interpret the results at each stage of the tutorial for deeper comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGW_BLfWa4Nr"
   },
   "source": [
    "### 1. Environment Setup\n",
    "\n",
    "__Step 1. Install libraries and packages__\n",
    "\n",
    "The \"pandas\" library provides powerful and easy-to-use data structures and data analysis tools\n",
    "- **Common Methods**\n",
    "    - `pd.DataFrame()`: Creates a new dataframe\n",
    "    - `pd.read_csv()`: Reads data from a csv file into a dataframe\n",
    "\n",
    "The `combinations` function from the \"itertools\" module is used to generate all possible combinations of a given iterable (like a list or set) of a specified length\n",
    "- **Parameter Settings**\n",
    "    - `iterable`: The iterable (like a list or set) from which combinations are generated\n",
    "    - `r`: The length of each combination. If not specified, it generates combinations of all possible lengths\n",
    "- **Usage Example**\n",
    "    - `combinations([1, 2, 3], 2)` would generate combinations of length 2 from the list `[1, 2, 3]`, resulting in `[(1, 2), (1, 3), (2, 3)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "179mRX7SOkU_"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries: pandas for data manipulation and combinations for creating combinations\n",
    "import pandas as pd\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOdfnzOsbDav"
   },
   "source": [
    "__Step 2. Load Data__\n",
    "\n",
    "Store the mock data that simulates transactions and user profiles\n",
    "\n",
    "`transactions`\n",
    "- **Purpose**: Represents a list of transactions where each transaction is a list of products bought in that particular transaction\n",
    "- **Type**: List of lists\n",
    "- **Usage**: This data structure will help simulate a basic transaction dataset: e`ach inner list is a representation of a single transaction and the products involved\n",
    "\n",
    "`users`\n",
    "- **Purpose**: Represents a dictionary of user profiles\n",
    "- **Type**: Dictionary\n",
    "    - **Keys**\n",
    "        - **`UserID`**: Unique identifier for each user\n",
    "        - **`Age`**: Age of the user\n",
    "        - **`Gender`**: Gender of the user\n",
    "        - **`Occupation`**: Occupation of the user\n",
    "- **Usage**: This dictionary simulates user profiles with attributes like age, gender, and occupation and can be converted into a DataFrame using `pandas` for further analysis and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJuaFM8NPJgF"
   },
   "outputs": [],
   "source": [
    "# Simulated transactions and user profiles for demonstration\n",
    "transactions = [\n",
    "    ['Milk', 'Bread', 'Eggs'],\n",
    "    ['Milk', 'Bread'],\n",
    "    ['Bread', 'Eggs', 'Juice'],\n",
    "    ['Milk', 'Juice', 'Cereal'],\n",
    "    ['Milk', 'Bread', 'Eggs', 'Cereal'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEC0jSh4OsnN"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate the product_counts series\n",
    "product_counts = pd.Series([item for sublist in transactions for item in sublist]).value_counts()\n",
    "print(product_counts)\n",
    "\n",
    "# Plot the product frequencies\n",
    "product_counts.plot(kind='bar', figsize=(10, 6), color='skyblue', edgecolor='black')\n",
    "plt.title('Frequency of Each Product in Sample Transactions')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Product')\n",
    "plt.yticks(np.arange(0, product_counts.max()+ 1, 1))\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yooh2f2maXJ3"
   },
   "outputs": [],
   "source": [
    "# Simulated user profiles\n",
    "users = {\n",
    "    'UserID': [1, 2, 3, 4, 5],\n",
    "    'Age': [25, 32, 45, 28, 39],\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'Occupation': ['Engineer', 'Doctor', 'Teacher', 'Lawyer', 'Engineer']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCfwM-g72ss0"
   },
   "outputs": [],
   "source": [
    "# Convert user profiles to a DataFrame\n",
    "user_df = pd.DataFrame(users)\n",
    "print(f\"User Profiles:\\n{user_df}\\n\")\n",
    "\n",
    "# Visualize user profiles by occupation\n",
    "user_df.groupby('Occupation').size().plot(kind='bar', figsize=(6, 4))\n",
    "plt.title('User Profiles by Occupation')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.xlabel('Occupation')\n",
    "plt.yticks(np.arange(0, user_df.groupby('Occupation').size().max() + 1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXcxCr-SSPzq"
   },
   "source": [
    "### 2. Apriori Algorithm Implementation\n",
    "\n",
    "__Step 1. Data Preparation__\n",
    "\n",
    "Transform the transactional data into a binary matrix representation that will be more suitable for the Apriori algorithm\n",
    "\n",
    "**`unique_products`**\n",
    "- **Purpose**: Generate a list of unique products across all transactions\n",
    "- **Function**: The inner list comprehension (`item for sublist in transactions for item in sublist`) flattens the transaction list. The outer `set` ensures that we only keep unique products. Finally, `sorted` arranges them in alphabetical order.\n",
    " - **Type**: List.\n",
    "- **Usage**: This list will serve as the columns for the binary matrix representation of transactions.\n",
    "\n",
    "**`pd.DataFrame()`**\n",
    "- **Purpose**: Convert data into a structured table (dataframe) for easier manipulation\n",
    "- **Function**: Creates a dataframe from provided data\n",
    "- **Parameters**\n",
    "    - **data**: Input data to be converted into a dataframe. Here, we use a list comprehension to generate the binary representation\n",
    "    - **columns**: Names of columns for the dataframe. Here, we use the `unique_products` list\n",
    "- **Usage**: The resulting `binary_df` dataframe will have a binary representation where rows correspond to transactions and columns to products. A \"1\" indicates the product was in the transaction, and \"0\" means it wasn't.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0do4HaH1aZYV"
   },
   "outputs": [],
   "source": [
    "# Get a list of all unique products across transactions\n",
    "unique_products = sorted(list(set(item for sublist in transactions for item in sublist)))\n",
    "\n",
    "# Create a binary matrix representation of transactions\n",
    "binary_df = pd.DataFrame([[1 if product in transaction else 0 for product in unique_products] for transaction in transactions], columns=unique_products)\n",
    "\n",
    "# Print the binary matrix representation\n",
    "print(\"Binary Matrix Representation:\")\n",
    "print(binary_df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Plot the frequency of each product in the binary matrix representation\n",
    "print(binary_df.sum())\n",
    "binary_df.sum().plot(kind='bar', figsize=(8, 4))\n",
    "plt.title('Frequency of Each Product in Transactions')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Product')\n",
    "plt.yticks(np.arange(0, binary_df.sum().max() + 1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phv6Xw4_bkpK"
   },
   "source": [
    "__Step 2. Apriori Algorithm__\n",
    "\n",
    "The Apriori algorithm identifies frequent itemsets from a transaction database. A frequent itemset is a set of one or more items that appear together in a significant number of transactions.\n",
    "\n",
    "`apriori_frequent_itemsets`\n",
    "- **Purpose**: Identifies the frequent itemsets in the transaction data\n",
    "- **Parameters**:\n",
    "    - **`data`**: The binary matrix representation of transactions\n",
    "    - **`min_support`** (default = 0.3): The minimum proportion of transactions in which an itemset needs to appear to be considered frequent\n",
    "- **Returns**: A list of frequent itemsets\n",
    "\n",
    "`combinations`\n",
    "- **Library**: `itertools`\n",
    "- **Purpose**: Generates all possible combinations of a given length from a list\n",
    "- **Usage**: Used to generate candidate itemsets of size `k` from the previously found frequent itemsets\n",
    "\n",
    "`num_transactions`\n",
    "- **Purpose**: Stores the total number of transactions\n",
    "- **Usage**: Used to calculate the support of itemsets\n",
    "\n",
    "`freq_1_itemsets`\n",
    "- **Purpose**: Stores the frequent 1-itemsets\n",
    "- **Usage**: This is the starting point. From here, the algorithm will look for larger itemsets.\n",
    "\n",
    "`candidates`\n",
    "- **Purpose**: A list of candidate itemsets generated from the frequent itemsets of the previous iteration\n",
    "- **Usage**: From these candidates, the algorithm will determine which ones are frequent in the current iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcg_GtjVaaGp"
   },
   "outputs": [],
   "source": [
    "# Implement the Apriori algorithm to find frequent itemsets\n",
    "def apriori_frequent_itemsets(data, min_support=0.3):\n",
    "    num_transactions = len(data)\n",
    "    num_items = len(data.columns)\n",
    "    frequent_itemsets = []\n",
    "\n",
    "    # 1-itemsets\n",
    "    freq_1_itemsets = data.loc[:, (data.sum(axis=0)/num_transactions) >= min_support].columns.tolist()\n",
    "    frequent_itemsets = [[item] for item in freq_1_itemsets]\n",
    "\n",
    "    k = 2\n",
    "    found_new_itemset = True\n",
    "    while found_new_itemset and k < num_items:\n",
    "        found_new_itemset = False\n",
    "        candidates = list(combinations(freq_1_itemsets, k))     # simplification: generates all combinations of size k\n",
    "        for candidate in candidates:\n",
    "            candidate_df = data[list(candidate)]\n",
    "            support = (candidate_df.sum(axis=1) == k).mean()    # sum of row values: 1 if transaction contains item, 0 otherwise\n",
    "            if support >= min_support:\n",
    "                print('Itemset', list(candidate), 'Support =', support)\n",
    "                frequent_itemsets.append(list(candidate))\n",
    "                found_new_itemset = True\n",
    "        k += 1\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "frequent_sets = apriori_frequent_itemsets(binary_df)\n",
    "print(f\"Frequent Itemsets:\\n{frequent_sets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSyIvLDMQOQ6"
   },
   "outputs": [],
   "source": [
    "# Count the frequency of each frequent itemset\n",
    "frequent_itemset_counts = pd.Series([(binary_df[itemset].sum(axis=1) == len(itemset)).sum()/len(transactions) for itemset in frequent_sets])\n",
    "\n",
    "# Plot the frequencies of frequent itemsets\n",
    "frequent_itemset_counts.plot(kind='bar', figsize=(8, 5), color='teal', edgecolor='black')\n",
    "plt.title('Support of Each Frequent Itemset')\n",
    "plt.ylabel('Support')\n",
    "plt.xlabel('Itemset')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDSlhu4bb9uP"
   },
   "source": [
    "__Step 3. Association Rule Generation__\n",
    "\n",
    "The next step is to generate association rules. These rules suggest that if certain items are bought (antecedents), other items (consequents) are likely to be bought as well. The confidence of an association rule A $\\rightarrow$ B is Support(A $\\cup$ B)/Support(A).\n",
    "\n",
    "`generate_rules`\n",
    "- **Purpose**: To generate association rules from the frequent itemsets\n",
    "- **Parameters**\n",
    "    - **`data`**: The binary matrix representation of transactions\n",
    "    - **`frequent_itemsets`**: The frequent itemsets identified using the Apriori algorithm\n",
    "    - **`min_confidence`** (default = 0.5): The minimum confidence threshold for a rule to be considered valid\n",
    "- **Returns**: A list of rules. Each rule is represented as a tuple with antecedent, consequent, and confidence\n",
    "\n",
    "`combinations`\n",
    "- **Purpose**: Used here to generate all possible antecedents for a given frequent itemset\n",
    "\n",
    "`antecedent_support` and `both_support`\n",
    "- **Purpose**: Calculate the support of the antecedent and the combined support of antecedent and consequent, respectively\n",
    "- **Usage**: These support values are required to compute the confidence of a rule\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QW14ia5maeaE"
   },
   "outputs": [],
   "source": [
    "# Function to generate association rules from frequent itemsets\n",
    "def generate_rules(data, frequent_itemsets, min_confidence=0.5):\n",
    "    rules = []\n",
    "    for itemset in frequent_itemsets:\n",
    "        for i in range(1, len(itemset)):\n",
    "            antecedents = list(combinations(itemset, i))\n",
    "            consequents = [tuple(set(itemset) - set(a)) for a in antecedents]\n",
    "            for antecedent, consequent in zip(antecedents, consequents):\n",
    "                antecedent_support = (data[list(antecedent)].sum(axis=1) == len(antecedent)).mean()\n",
    "                both_support = (data[list(itemset)].sum(axis=1) == len(itemset)).mean()\n",
    "                confidence = both_support / antecedent_support\n",
    "                if confidence >= min_confidence:\n",
    "                    rules.append((antecedent, consequent, confidence))\n",
    "    return rules\n",
    "\n",
    "rules = generate_rules(binary_df, frequent_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESME2OSTRVm4"
   },
   "outputs": [],
   "source": [
    "# Print the association rules\n",
    "print(\"Association Rules (antecedent -> consequent with confidence):\\n\")\n",
    "for antecedent, consequent, confidence in rules:\n",
    "    print(f\"{antecedent} -> {consequent} with confidence {confidence:.2f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Visualize the distribution of rule confidences\n",
    "confidences = [rule[2] for rule in rules]\n",
    "(n, bins, patches) = plt.hist(confidences, bins=10, edgecolor='black')\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Number of Rules')\n",
    "plt.yticks(np.arange(0, n.max() + 1, 1))\n",
    "plt.title('Distribution of Rule Confidences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1FFCdmacdfC"
   },
   "source": [
    "### 3. User Profile-Based Recommendations\n",
    "\n",
    "__Step 1. Recommendations__\n",
    "\n",
    "We enhance our recommendations by considering user profiles. Personalizing recommendations based on user attributes (like age, gender, occupation) can improve recommendation relevance. For each rule, if the antecedent is a subset of `cart_items`, we add the consequent to the recommendations. This means that if a user has items in their cart that match the antecedent of a rule, we recommend the consequent items. Depending on the user's occupation and age, we might add specific items to the recommendations. For example, if the user is an engineer, we might recommend \"Technical Books\".\n",
    "\n",
    "`user_based_recommendations`\n",
    "- **Purpose**: To generate personalized product recommendations based on the user's profile and the items in their cart\n",
    "- **Parameters**:\n",
    "    - **`user_profile`**: A dictionary containing user attributes\n",
    "    - **`cart_items`**: List of items currently in the user's cart\n",
    "    - **`rules`**: Association rules generated earlier\n",
    "- **Returns**: A list of recommended items.\n",
    "\n",
    "`recommendations.difference`\n",
    "- This ensures that we don't recommend items that are already in the user's cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Zy5bUehaiGt"
   },
   "outputs": [],
   "source": [
    "# Function to provide user-based recommendations considering:\n",
    "# 1. Association rules based on products in the user's cart,\n",
    "# 2. Specific recommendations based on user's profile.\n",
    "def user_based_recommendations(user_profile, cart_items, rules):\n",
    "    recommendations = set()\n",
    "\n",
    "    # Association rules\n",
    "    for antecedent, consequent, _ in rules:\n",
    "        if set(antecedent).issubset(set(cart_items)):\n",
    "            recommendations.update(consequent)\n",
    "\n",
    "    # User profile example\n",
    "    if user_profile['Occupation'] == 'Engineer':\n",
    "        recommendations.add('Technical Books')\n",
    "    elif user_profile['Occupation'] == 'Doctor':\n",
    "        recommendations.add('Medical Supplies')\n",
    "    elif 20 <= user_profile['Age'] <= 30:\n",
    "        recommendations.add('Energy Drink')\n",
    "\n",
    "    recommendations = recommendations.difference(set(cart_items))\n",
    "    return list(recommendations)\n",
    "\n",
    "for antecedent, consequent, confidence in rules:\n",
    "    print(f\"{antecedent} -> {consequent} with confidence {confidence:.2f}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBA1IwvncmoJ"
   },
   "source": [
    "__Step 2. Recommendations with User Profiles__\n",
    "\n",
    "We test our user profile-based recommendation system with a sample user profile and list of items in their cart to see what the system suggests for them.\n",
    "\n",
    "**Sample User Profile and Cart**\n",
    "- **`user_profile_sample`**: A dictionary containing the profile of a sample user. The user is a 25-year-old male engineer.\n",
    "- **`cart_sample`**: A list representing the items currently in the sample user's cart. This user has \"Milk\" and \"Bread\" in their cart.\n",
    "\n",
    "`user_based_recommendations`\n",
    "- The function `user_based_recommendations` is called with the sample user profile, cart items and previously generated rules\n",
    "- The function will then provide product recommendations based on association rules and the user's profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkeOprk3am9R"
   },
   "outputs": [],
   "source": [
    "# Sample user profile and cart for demonstration\n",
    "user_profile_sample = {'UserID': 1, 'Age': 25, 'Gender': 'Male', 'Occupation': 'Engineer'}\n",
    "cart_sample = ['Milk', 'Bread']\n",
    "\n",
    "# Get personalized recommendations for the sample user\n",
    "personal_recommendations = user_based_recommendations(user_profile_sample, cart_sample, rules)\n",
    "print(f\"For a user with profile:\\n{user_profile_sample}\\n\")\n",
    "print(f\"Having items {cart_sample} in their cart, the system recommends:\\n{personal_recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PDSFeb1qhs0"
   },
   "source": [
    "## Discussion Questions\n",
    "\n",
    "1. **Parameter Tuning**\n",
    "    - Try adjusting the `min_support` and `min_confidence` parameters in the Apriori algorithm.\n",
    "    - What differences do you observe with a higher/lower `min_support`?\n",
    "    - How does changing the `min_confidence` to 0.2 compare to 0.8 affect the association rules generated?\n",
    "    - Draw an analogy to precision and recall to explain the differences.\n",
    "2. **Profile-Based Recommendations**\n",
    "    - Assume we could generate such association rules from transactions data.\n",
    "    - Would association rules of this nature produce \"better\" recommendations for all users?\n",
    "    - Would such association rules help address cold start problem for users?\n",
    "    - Again consider the precision/recall trade-off?\n",
    "3. **New Metrics**\n",
    "    - Add a \"lift\" metric to evaluate the association rules (Google it!).\n",
    "    - How does \"lift\" compare to \"confidence\" in gauging the quality of a rule?\n",
    "    - Try filtering rules based on a minimum \"lift\" value.\n",
    "    - How does this filter compare to using confidence?\n",
    "    - What difference would this make to the recommendations?\n",
    "4. **Alternative Applications**\n",
    "    - Consider extending `user_based_recommendations` to use additional user attributes?\n",
    "    - Think about including browsing history or past product ratings.\n",
    "    - How might you generate recommendations based on a user's past browsing?\n",
    "    - Can you design a method to prioritize recommendations using both association rules and a user's product ratings?\n",
    "5. **Visual Insight into Rules**\n",
    "    - Design a function that can visually display the association rules.\n",
    "    - This might be a graph, heatmap or any other visualization.\n",
    "    - Which visualization would help you understand product relationships best?\n",
    "    - Can you design a visualization that shows only the top 10 rules with the highest confidence?\n",
    "6. **Learning from User Feedback**\n",
    "    - Imagine users can give feedback on your recommendations. How would you incorporate this feedback to improve future suggestions?\n",
    "    - If a user regularly dismisses a recommendation, how should the system respond?\n",
    "    - Think about how you might prioritize products that consistently receive positive feedback.\n",
    "\n",
    "## Advanced\n",
    "\n",
    "1. Think about the analogy between association rule mining and item-based collaborative filtering. How do these methods differ and what are their respective strengths and weaknesses?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
