{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMP9517 24T3 Lab 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jinghan Wang (z5286124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:35.723529Z",
     "start_time": "2024-09-27T06:35:35.721625Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:35.734947Z",
     "start_time": "2024-09-27T06:35:35.732814Z"
    }
   },
   "outputs": [],
   "source": [
    "def pic_show(img1, img2):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.title('Input')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.title('Output')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 (0.75 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your friend has been invited to participate in an art project called “Balance in Brightness” that involves creating and comparing images with their “antiforms”. He has captured a nice picture of dark trees against a bright sky and snowy mountains during daylight (see the picture below on the left) and he asks you to help him with his project.\n",
    "\n",
    "The idea is to create a nighttime version of the picture, where the tree and its immediate surroundings are illuminated but the background is now dark (see the result below on the right). Use intensity inversion and gamma correction to accomplish this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:36.420579Z",
     "start_time": "2024-09-27T06:35:35.742825Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/Task1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Intensity Inversion\n",
    "inverse = 255 - image\n",
    "\n",
    "# Gamma Correction\n",
    "gamma = 0.3\n",
    "table = np.array([((i / 255.0) ** (1.0 / gamma)) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "pic_show(image, cv2.LUT(inverse, table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 (0.75 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your friends met Jasper at the main library last week and took a lot of pictures with him. When they returned home and looked through their photos, they saw the camera bugged out and one of the photos (see below) was very noisy. You are asked to help them restore the photo.\n",
    "\n",
    "As you remember from the computer vision course, there are different filtering methods to reduce noise in images, such as mean (uniform), Gaussian, and median filtering. Experiment with these filtering methods to find out which one best reduces the noise in this photo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:36.449458Z",
     "start_time": "2024-09-27T06:35:36.436161Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/Task2.jpg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian Blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:36.777102Z",
     "start_time": "2024-09-27T06:35:36.455510Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Input')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(cv2.blur(image, (5, 5)), cmap='gray')\n",
    "plt.title('Mean (Uniform)')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(cv2.GaussianBlur(image, (9, 9), 0), cmap='gray')\n",
    "plt.title('Gaussian')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(cv2.medianBlur(image, 3), cmap='gray')\n",
    "plt.title('Median')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median filtering replaces the current pixel value with the median of the surrounding pixels, effectively removing extreme noise values without blurring the entire region. In cases of heavy noise, using mean or Gaussian filters can cause excessive blurring, as these methods calculate an average, allowing noise to spread across the region. Median filtering is better at preserving edges and details in noisy images, as it avoids incorporating extreme noise values into the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:37.049672Z",
     "start_time": "2024-09-27T06:35:36.792832Z"
    }
   },
   "outputs": [],
   "source": [
    "pic_show(image, cv2.medianBlur(image, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 (0.75 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another one of your friend’s vacation pictures (see below) was a bit blurred. You remember from the course that there are different methods to sharpen images, such as unsharp masking and by using the Laplacean filter, so you decide to try these out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:37.074651Z",
     "start_time": "2024-09-27T06:35:37.066366Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/Task3.jpg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Laplacian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:37.082286Z",
     "start_time": "2024-09-27T06:35:37.080058Z"
    }
   },
   "outputs": [],
   "source": [
    "def laplacian_mask(image, ksize=3, alpha=1, beta=-0.5):\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F, ksize=ksize)\n",
    "    laplacian_abs = cv2.convertScaleAbs(laplacian)\n",
    "    sharpened_image = cv2.addWeighted(image, alpha, laplacian_abs, beta, 0)\n",
    "    return sharpened_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unsharp Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:37.089453Z",
     "start_time": "2024-09-27T06:35:37.087296Z"
    }
   },
   "outputs": [],
   "source": [
    "def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=10):\n",
    "    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "    sharpened = cv2.addWeighted(image, 1 + amount, blurred, -amount, 0)\n",
    "    return sharpened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:37.708037Z",
     "start_time": "2024-09-27T06:35:37.094648Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Input')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(unsharp_mask(image), cmap='gray')\n",
    "plt.title('Unsharp Mask Shape')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(laplacian_mask(image, beta=1.5), cmap='gray')\n",
    "plt.title('Laplacian Shape (Bright Edge)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(laplacian_mask(image, beta=-1.5), cmap='gray')\n",
    "plt.title('Laplacian Shape (Dark Edge)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the result, When there are both white and black edges, the Laplacian filter is less effective than Unsharp Masking because of how it handles edge transitions. The Laplacian filter detects both positive (light-to-dark) and negative (dark-to-light) transitions, resulting in opposite signs for white and black edges. This can lead to artifacts, such as “double edges” or unwanted dark or bright halos around the edges, making the sharpening effect uneven.\n",
    "\n",
    "In contrast, Unsharp Masking works by subtracting a blurred version of the image from the original, which enhances the edges more uniformly. It avoids the strong negative and positive responses of the Laplacian, resulting in a cleaner and more consistent sharpening effect across both light and dark edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T06:35:38.054590Z",
     "start_time": "2024-09-27T06:35:37.721356Z"
    }
   },
   "outputs": [],
   "source": [
    "pic_show(image, unsharp_mask(image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
