{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e278512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14e8f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I love you', {'label': 'LABEL_2', 'score': 0.9557049870491028})\n",
      "('I ate cereal for breakfast', {'label': 'LABEL_1', 'score': 0.768639862537384})\n",
      "('I hate you', {'label': 'LABEL_0', 'score': 0.965427041053772})\n"
     ]
    }
   ],
   "source": [
    "#COMP6713 24T1\n",
    "# This program show how HuggingFace pipelines can be used\n",
    "\n",
    "# Example of text classification. Input: Sequence, output: Label\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "data = [\"I love you\", \"I ate cereal for breakfast\", \"I hate you\"]\n",
    "res = sentiment_pipeline(data)\n",
    "for i in zip(data, res):\n",
    "\tprint(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b30e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c084c6f6474458e9613c2f46797835a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9965899586677551, 'start': 41, 'end': 49, 'answer': 'Canberra'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of text extraction. Input: Sequence, output: Phrase in the sequence\n",
    "# Use of a model pipeline without a model name is not recommended. The below is only a simple example.\n",
    "qa_pipeline = pipeline(\"question-answering\")\n",
    "question = \"What is the capital of Australia?\"\n",
    "context = \"The weather in Australia's capital city, Canberra, is pleasant today.\"\n",
    "\n",
    "res = qa_pipeline(question =  question, context = context)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cf999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142a88d7380644ca85c787666f2558b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-ORG', 'score': 0.99777824, 'index': 1, 'word': 'University', 'start': 0, 'end': 10}, {'entity': 'I-ORG', 'score': 0.9964133, 'index': 2, 'word': 'of', 'start': 11, 'end': 13}, {'entity': 'I-ORG', 'score': 0.99850214, 'index': 3, 'word': 'New', 'start': 14, 'end': 17}, {'entity': 'I-ORG', 'score': 0.9936692, 'index': 4, 'word': 'South', 'start': 18, 'end': 23}, {'entity': 'I-ORG', 'score': 0.9954946, 'index': 5, 'word': 'Wales', 'start': 24, 'end': 29}, {'entity': 'B-LOC', 'score': 0.99470913, 'index': 8, 'word': 'Sydney', 'start': 36, 'end': 42}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of seq2seq generation. Input: Sequence, Output: Sequence of the same length\n",
    "\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "res = ner_pipeline(\"University of New South Wales is in Sydney\")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4eb331d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Natural language processing is a branch of artificial intelligence that deals with computational approaches used to process text. Ambiguity resolution using computational techniques is at the heart of NLP. The advancements in NLP can be visualized as three generations: rule-based, statistical and neural.'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of seq2seq generation. Input: Sequence, Output: Shorter sequence\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "document = \"Natural language processing (NLP) is a branch of artificial intelligence that deals with computational approaches used to process text. Human language (i.e., natural language) is inherently ambiguous. Ambiguity resolution using computational techniques is at the heart of NLP. As a result, the advancements in NLP can be visualized as three generations: rule-based, statistical and neural. The course introduces the three generations of NLP through the philosophy of ambiguity resolution being the core task of NLP. The content covers different NLP sub-problems (such as POS tagging, sentiment classification, named entity recognition, machine translation and summarisation), and typical approaches in the three generations to tackle these sub-problems. With recent advancements in large language models, there has been a renewed interest in NLP from industry and research alike. However, NLP precedes large language models. The exposition of NLP centered around ambiguity resolution helps to develop an understanding of the past and the present of NLP.\"\n",
    "\n",
    "print(summarizer(document, max_length=130, min_length=30, do_sample=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450a6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
